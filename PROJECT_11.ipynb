{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "E32NKwKm3CUb",
        "n-C3VO3A3Mr5",
        "k5oohhCI5Axk"
      ],
      "toc_visible": true,
      "history_visible": true,
      "mount_file_id": "1Q2nAnizHQ62-KIt0LpFtffZpzgqvL267",
      "authorship_tag": "ABX9TyOT9v1h+X74MkXMphUVULD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azhare88/azhare88/blob/main/PROJECT_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mechine Learning - Sarti Baduy Effect - Vm.co"
      ],
      "metadata": {
        "id": "BpE3pe-1mxfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Youtube Content"
      ],
      "metadata": {
        "id": "E32NKwKm3CUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Youtube Content**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B1rqKoktnbY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Channel yang membuat content Sarti Baduy :\n",
        "1. Channel Vilmei\n",
        "    *   3.473k Views (9/6/24)\n",
        "    *   1.653K Views (10/6/24)\n",
        "\n",
        "2. Channel Nikita Mirzani\n",
        "    *   1.332k Views (4/7/24)\n",
        "    *   558K Views (5/7/24)\n",
        "    *   434K Views (7/7/24)\n",
        "\n",
        "3. Trans tv official\n",
        "    *   205k Views (6/7/24)\n",
        "    *   73K Views (6/7/24)\n",
        "    *   110K Views (6/7/24)\n",
        "\n",
        "4. Channel Ego Adriano\n",
        "    *   85K Views (12/7/24)\n",
        "    *   108K Views (22/6/24)\n"
      ],
      "metadata": {
        "id": "egypIcOSqIJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import googleapiclient.discovery # type: ignore\n",
        "import googleapiclient.errors # type: ignore\n"
      ],
      "metadata": {
        "id": "VtLIp5ws2ExD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS39m-GCmtyH"
      },
      "outputs": [],
      "source": [
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = \"AIzaSyDHT1nwRQolUacQt4ANrJCUfuEYEdUtEXY\"\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\n",
        "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "# Function to fetch comments\n",
        "def fetch_comments(video_id):\n",
        "    comments = []\n",
        "    request = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=\"9pvn3FPLZ6g\",\n",
        "        maxResults=43163  # Maximum allowed value\n",
        "    )\n",
        "\n",
        "    while request:\n",
        "        response = request.execute()\n",
        "        # Collect comments\n",
        "        for item in response['items']:\n",
        "            comments.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
        "\n",
        "        # Check if there is a next page\n",
        "        request = youtube.commentThreads().list_next(request, response)\n",
        "\n",
        "    return comments\n",
        "\n",
        "# Fetch comments for a specific video ID\n",
        "video_id = \"9pvn3FPLZ6g\"\n",
        "all_comments = fetch_comments(video_id)\n",
        "\n",
        "# Save comments to Excel\n",
        "df = pd.DataFrame(all_comments, columns=['Comment'])\n",
        "excel_file = 'youtube_comments.xlsx'\n",
        "df.to_excel(excel_file, index=False, engine='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comment_excel = pd.read_excel('/content/youtube_comments.xlsx')\n",
        "comment_excel"
      ],
      "metadata": {
        "id": "NQZySOJV2MwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = pd.DataFrame(comment_excel)\n",
        "comment"
      ],
      "metadata": {
        "id": "jk0Qf5lr2tkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Cleaning Data**"
      ],
      "metadata": {
        "id": "mBGuu2Lz5p-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment.shape"
      ],
      "metadata": {
        "id": "25fi-WaS2WtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = comment.drop_duplicates(subset=['Comment'])"
      ],
      "metadata": {
        "id": "YzKTqWvbo9qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment.duplicated().sum()"
      ],
      "metadata": {
        "id": "rbXItoVd6MVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = comment.dropna()"
      ],
      "metadata": {
        "id": "gIb9-vie6QC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment.isnull().sum()"
      ],
      "metadata": {
        "id": "XcMaVGXr6TlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment.shape"
      ],
      "metadata": {
        "id": "4bVX__hZ6ZsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_youtube_comment(text):\n",
        "    # Split the input text into lines\n",
        "    lines = text.splitlines()\n",
        "    cleaned_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Remove mentions, hashtags, retweets, and URLs\n",
        "        line = re.sub(r'@[A-Za-z0-9_]+', ' ', line)\n",
        "        line = re.sub(r'#\\W+', ' ', line)\n",
        "        line = re.sub(r'RT[\\s]+', ' ', line)\n",
        "        line = re.sub(r'https?://\\S+', ' ', line)\n",
        "\n",
        "        # Remove non-alphanumeric characters (except spaces)\n",
        "        line = re.sub(r'[^A-Za-z0-9 ]+', ' ', line)\n",
        "\n",
        "        # Remove words with repeating characters (e.g., \"hampirrrr\" -> \"hampir\")\n",
        "        line = re.sub(r'(.)\\1{2,}', r'\\1', line)  # Reduce three or more repeating characters to one\n",
        "\n",
        "        # Remove extra spaces\n",
        "        line = re.sub(r'\\s+', ' ', line).strip()\n",
        "\n",
        "        # Check if the line is only digits or empty\n",
        "        if line.isdigit() or not line:\n",
        "            continue\n",
        "\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    # Join the cleaned lines back into a single string\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "comment['Comment'] = comment['Comment'].apply(clean_youtube_comment)\n"
      ],
      "metadata": {
        "id": "4yuh08US6eqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment['Comment'] = comment['Comment'].str.lower()"
      ],
      "metadata": {
        "id": "t2Ve9KaA7BgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment"
      ],
      "metadata": {
        "id": "Hbb8196u7Ih6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Preprocessing**"
      ],
      "metadata": {
        "id": "NkzEL61b7MlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalisasi\n",
        "\n",
        "norm = {\" yg \":\" yang \", ' nggak ':' tidak ', \" gak \":\" tidak \",\" mansion \":\" rumah mewah \",\" bangetdari \":\" banget \",\" vibes \":\" suasana \",\" mantab \":\" keren \",\" In Sha ALLAH \":\" InsyaAllah \", \" bgt \" : \" banget \", \" tp \" : \" tapi \", \" mbk \" : \" ibu \", \" hrs \" : \" harus \", \" bngt \" : \" banget \", \" cpt \" : \" cepet \", \" tdk \":\" tidak \",\" mbak \":\" ibu \", \" amat \":\" banget \", \" pager \":\" pagar \"}\n",
        "\n",
        "def normalisasi(str_text):\n",
        "  for i in norm:\n",
        "    str_text = str_text.replace(i, norm[i])\n",
        "  return str_text\n",
        "\n",
        "comment['Comment'] = comment['Comment'].apply(lambda x: normalisasi(x))\n",
        "comment"
      ],
      "metadata": {
        "id": "SjsfHfv77U-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install Sastrawi"
      ],
      "metadata": {
        "id": "sb59owzi7ubU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords\n",
        "import Sastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n"
      ],
      "metadata": {
        "id": "0hAHqJcs8FZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "more_stop_words = [\"tidak\", \"yang\", \"br\"]\n",
        "\n",
        "stop_words = StopWordRemoverFactory().get_stop_words()\n",
        "stop_words.extend(more_stop_words)\n",
        "\n",
        "new_array = ArrayDictionary(stop_words)\n",
        "stop_words_remover_new = StopWordRemover(new_array)\n",
        "\n",
        "def stopword(str_text):\n",
        "  str_text = stop_words_remover_new.remove(str_text)\n",
        "  return str_text\n",
        "\n",
        "comment['Comment'] = comment['Comment'].apply(lambda x: stopword(x))\n",
        "comment.head()"
      ],
      "metadata": {
        "id": "1vX6XNr-8Kb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize\n",
        "tokenized = comment['Comment'].apply(lambda x:x.split())\n",
        "tokenized"
      ],
      "metadata": {
        "id": "lohNO7si8d7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "def stemming(text_cleaning):\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  do = []\n",
        "  for w in text_cleaning:\n",
        "    dt = stemmer.stem(w)\n",
        "    do.append(dt)\n",
        "  d_clean = []\n",
        "  d_clean = ' '.join(do)\n",
        "  print(d_clean)\n",
        "  return d_clean\n",
        "\n",
        "tokenized = tokenized.apply(stemming)\n",
        "\n",
        "tokenized.to_excek('/content/comments_stemming.xlsx', index=False)"
      ],
      "metadata": {
        "id": "JAZr3Kou8lFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_steming = pd.read_csv('/content/comments_stemminggg.csv')\n",
        "data_steming"
      ],
      "metadata": {
        "id": "KIPqbqjDFEbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/comments_stemminggg.csv')\n",
        "df1"
      ],
      "metadata": {
        "id": "qG6xE3qdDAos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_excel('/content/comments_stemmingg.xlsx', index=False)"
      ],
      "metadata": {
        "id": "kukj2BkyDUny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 . Translate**"
      ],
      "metadata": {
        "id": "-0Imw2IPFT3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translated_comments = pd.read_excel('/content/baduy_comments_translate.xlsx')\n",
        "translated_comments"
      ],
      "metadata": {
        "id": "3PDAgz7zFXK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Labeling**"
      ],
      "metadata": {
        "id": "zDCXVACDHIfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweet-preprocessor\n",
        "!pip install textblob\n",
        "!pip install wordcloud\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "GCLUgYLzHNiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import preprocessor as p\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "6RaJwl-EHUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "comment_youtube = list(translated_comments['Comment'])\n",
        "polaritas = 0\n",
        "\n",
        "status = []\n",
        "total_positif = total_negatif = total_netral = total = 0\n",
        "\n",
        "for i, youtube in enumerate(comment_youtube):\n",
        "    youtube = str(youtube)  # Convert the tweet to a string\n",
        "    analysis = TextBlob(youtube)\n",
        "    polaritas += analysis.polarity\n",
        "\n",
        "    if analysis.sentiment.polarity > 0.0:\n",
        "        total_positif += 1\n",
        "        status.append('Positif')\n",
        "    elif analysis.sentiment.polarity == 0.0:\n",
        "        total_netral += 1\n",
        "        status.append('Netral')\n",
        "    else:\n",
        "        total_negatif += 1\n",
        "        status.append('Negatif')\n",
        "    total += 1\n",
        "\n",
        "print(f'Hasil Analysis Data:\\nPositif = {total_positif}\\nNetral = {total_netral}\\nNegatif = {total_negatif}')\n",
        "print(f'\\nTotal Data : {total}')\n"
      ],
      "metadata": {
        "id": "Jh9WohkqHX5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_comments['klasifikasi'] = status\n",
        "translated_comments"
      ],
      "metadata": {
        "id": "4QMRdpYhIAs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translated_comments.columns)"
      ],
      "metadata": {
        "id": "a6RhgZKuJuZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cloud(wordcloud):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Convert all items to strings before joining them\n",
        "all_words = ' '.join([str(tweets) for tweets in translated_comments['Comment']])\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    width=3000,\n",
        "    height=2000,\n",
        "    random_state=3,\n",
        "    background_color='white',\n",
        "    colormap='Blues_r',\n",
        "    collocations=False,\n",
        "    stopwords=STOPWORDS\n",
        ").generate(all_words)\n",
        "\n",
        "plot_cloud(wordcloud)\n"
      ],
      "metadata": {
        "id": "UJGKwyK9Jz9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Excel file\n",
        "df = pd.read_excel('/content/baduy_comments_translate.xlsx')\n",
        "\n",
        "# Assuming the text data is in a specific column (replace 'comments' with the correct column name)\n",
        "text = \" \".join(df['Comment'].dropna().astype(str))\n",
        "\n",
        "# Define a function to set the word color to black\n",
        "def black_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "    return(\"hsl(0, 100%, 1%)\")\n",
        "\n",
        "# Generate the word cloud\n",
        "wc = WordCloud(background_color=\"white\",           # select background color\n",
        "               width=3000,                         # set width\n",
        "               height=2000,                        # set height\n",
        "               max_words=500).generate(text)       # set max amount of words\n",
        "\n",
        "# Apply the black color function\n",
        "wc.recolor(color_func=black_color_func)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=[15, 10])\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.savefig('wordcloud.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZwAKdGYHOKEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Google Search"
      ],
      "metadata": {
        "id": "n-C3VO3A3Mr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Baduy**"
      ],
      "metadata": {
        "id": "t6x6VRFnZPlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengatur ulang plotting dan menyimpan file dalam direktori yang sesuai\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "doLXRXhBaM5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(baduy_search.columns)\n"
      ],
      "metadata": {
        "id": "6kjr_5oMxk8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from io import StringIO\n",
        "\n",
        "# Convert the string to a DataFrame\n",
        "baduy_search = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fille/Baduy_search.csv')\n",
        "\n",
        "# Mengubah data menjadi DataFrame\n",
        "df = pd.DataFrame(data, columns=['date', 'value'])\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['date'], df['value'], marker='o', linestyle='-', color='b')\n",
        "plt.title('Baduy Google Search')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('value')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tW6-YE97c1Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Sarti Baduy**"
      ],
      "metadata": {
        "id": "gIbjnSIHc8ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memastikan direktori tujuan ada\n",
        "output_dir = '/mnt/data/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Data yang akan digunakan\n",
        "data = [\n",
        "    [\"2024-05-05\", 0],\n",
        "    [\"2024-05-12\", 0],\n",
        "    [\"2024-05-19\", 0],\n",
        "    [\"2024-05-26\", 0],\n",
        "    [\"2024-06-02\", 0],\n",
        "    [\"2024-06-09\", 0],\n",
        "    [\"2024-06-16\", 25],\n",
        "    [\"2024-06-23\", 100],\n",
        "    [\"2024-06-30\", 28],\n",
        "    [\"2024-07-07\", 0],\n",
        "    [\"2024-07-14\", 14],\n",
        "    [\"2024-07-21\", 0],\n",
        "    [\"2024-07-28\", 0],\n",
        "    [\"2024-08-04\", 0],\n",
        "    [\"2024-08-11\", 1],\n",
        "    [\"2024-08-18\", 4],\n",
        "    [\"2024-08-25\", 3]\n",
        "]\n",
        "\n",
        "# Mengubah data menjadi DataFrame\n",
        "df = pd.DataFrame(data, columns=['Date', 'Value'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['Value'], marker='o', color='orange')\n",
        "plt.title('Sarti Baduy Google Search')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Menyimpan plot ke file\n",
        "save_path = os.path.join(output_dir, 'time_series_plot.png')\n",
        "plt.savefig(save_path)\n",
        "\n",
        "save_path"
      ],
      "metadata": {
        "id": "UwmZbNFfPEDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Rumsyah Baduy**"
      ],
      "metadata": {
        "id": "0COuzuhhaowd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Combined data from both sets\n",
        "data = {\n",
        "    \"date\": [\n",
        "        \"2024-05-05\", \"2024-05-12\", \"2024-05-19\", \"2024-05-26\",\n",
        "        \"2024-06-02\", \"2024-06-09\", \"2024-06-16\", \"2024-06-23\",\n",
        "        \"2024-06-30\", \"2024-07-07\", \"2024-07-14\", \"2024-07-21\",\n",
        "        \"2024-07-28\", \"2024-08-04\", \"2024-08-11\", \"2024-08-18\",\n",
        "        \"2024-08-25\"\n",
        "    ],\n",
        "    \"value\": [\n",
        "        0, 0, 0, 0,\n",
        "        0, 0, 100,\n",
        "        8, 4, 0, 0,\n",
        "        0, 0, 0, 0,\n",
        "        1, 0]\n",
        "}\n",
        "\n",
        "# Convert data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['date'], df['value'], marker='o', linestyle='-', color='blue')\n",
        "plt.title('Rumsyah Baduy Google Search')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the plot\n",
        "save_path = '/mnt/data/time_series_plot.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "save_path\n"
      ],
      "metadata": {
        "id": "kVasL51IaOq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r8WouFwrarPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4N0aTa7dbnlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tiktok Content"
      ],
      "metadata": {
        "id": "kqmT5gn84uwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Content Sarti Tiktok di vm.**co**\n",
        "\n",
        "  Like : 287.8K\n",
        "  \n",
        "  Comments : 590\n",
        "  \n",
        "  Archive : 11.6K"
      ],
      "metadata": {
        "id": "qkrW52Btnmhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Data\n",
        "data = [\n",
        "    ('A&Y', 'muntahan ikan paus emg wangi uyyğŸ™‚', '1550'),\n",
        "    ('ğ©ğ¢ğšğšğ€ğš_', '\"yg bikin wangi nya tahan lama\"', '81'),\n",
        "    ('ifaa', 'aelah malah ada si rumsyah', '51'),\n",
        "    ('chillağŸœ', 'ğŸ—¿', '1'),\n",
        "    ('salbiabilra', 'Lebih suka sarti dari pada rumsahğŸ˜‚', '2094'),\n",
        "    ('jeje', 'iyaa weh', '0'),\n",
        "    ('yaooğŸ’¤', 'benerrr', '0'),\n",
        "    ('ChikaVelisyaPutri1', 'rumsah teh Saha kak ğŸ˜‚ğŸ˜‚', '7'),\n",
        "    ('Inii alleaa á¯“á¡£ğ­©', 'Sarti ramah bet jir', '21.7K'),\n",
        "    ('ğ’“ğ’Šğ’‡ğ’‚ğ’‚', 'ğŸ˜­', '1'),\n",
        "    ('sal', 'ğŸ—¿', '0'),\n",
        "    ('Inii alleaa á¯“á¡£ğ­©', 'Iyyaaah tadi dia emang ramah juga', '9'),\n",
        "    ('haaru.', 'Dia kek emang friendly gasii?', '28'),\n",
        "    ('TANiğŸ…°ï¸', 'rumsyah keknya malu2 wkwk bingung harus apa gt', '10'),\n",
        "    ('à»ˆsartii', 'sarti aku kahhğŸ˜­ğŸ—¿', '70'),\n",
        "    ('jaehyun\\'s gf', 'iyaa friendly, bukan sasimo', '7'),\n",
        "    ('Inii alleaa á¯“á¡£ğ­©', 'Tpi bukannya gmn ya dia kalo ci vilmei ngomong ga natep gtu kayak malah madep madep ke arah lain', '2'),\n",
        "    ('Inii alleaa á¯“á¡£ğ­©', 'BUKAN BUKAN', '55'),\n",
        "    ('PERSIJAXğŸ‡µğŸ‡­ğŸ‡µğŸ‡­ğŸ‡µğŸ‡­', 'oh gitu', '2'),\n",
        "    ('PERSIJAXğŸ‡µğŸ‡­ğŸ‡µğŸ‡­ğŸ‡µğŸ‡­', 'iyah daripada rumsyahğŸ—¿', '59'),\n",
        "    ('IG : nandabllaa_', 'knpa ga kasih hp ke sarti aja ciğŸ™‚ğŸ˜­', '7505'),\n",
        "    ('ï¸ï¸ï¸', 'sebelah di kasih satu permintaan eh malah minta 2 permintaanğŸ—¿', '217'),\n",
        "    ('IG : nandabllaa_', 'owh gtu ya, tpi sblah ngmng bisa gtu yağŸ˜­', '220'),\n",
        "    ('ğŸ’', 'mybe sarti ga minta,kan sblah minta', '886'),\n",
        "    ('hizkia devariel G', 'lebih suka lihat sarti...', '2166'),\n",
        "    ('ğ˜¿ğ™ğ™‡', 'Cantik bet sardiğŸ¥µ', '195'),\n",
        "    ('Rahayu anggara', 'sardi Saha..Sardi mah tatangga urang ğŸ˜­', '1'),\n",
        "    ('rosejke', 'sardi? sarden kali ah', '1'),\n",
        "    ('melaa', '@sisrmdn', '0'),\n",
        "    ('faaaaaaa.xxxxxxxx', 'ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­', '0'),\n",
        "    ('ğ–†ğ–“ğ–Œğ–Šğ–‘ğ–‘ğ–‘ğ–‘_ğ–‹ğ–—ğ–Šğ–“ğ–“', 'Sardi kakek ku woylahğŸ˜­', '2'),\n",
        "    ('PuteeeğŸ’«ğŸˆ', 'kok nangis sih. ikutan juga lahğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­', '0'),\n",
        "    ('Unknown', 'sarti ey ğŸ˜…ğŸ˜…', '1'),\n",
        "    ('heycipaaaa', 'WKWKWğŸ˜­ğŸ˜­', '1'),\n",
        "    ('bysaa ğ™š', 'satiiiğŸ˜­', '2'),\n",
        "    ('ğ˜¿ğ™ğ™‡', 'biruğŸ—¿', '0'),\n",
        "    ('@ğ™šË™â‹† mayy', 'km jgg typo bjrrğŸ˜­', '21'),\n",
        "    ('keysaa?ğŸ’', 'cantik cantik namanya Sardi ğŸ—¿ğŸ™', '3'),\n",
        "    ('â˜…Dreammie_ANAA', 'singkat padat sardi ğŸ—¿', '1'),\n",
        "    ('ğŸ§ ', 'plis ngakakğŸ˜­ğŸ˜­ğŸ™', '5'),\n",
        "    ('ğ˜¿ğ™ğ™‡', 'ğŸ—¿', '1'),\n",
        "    ('cicak kejepitğŸ', 'satii kakk sartii bukan sardiğŸ˜­ğŸ˜­ğŸ˜­', '37'),\n",
        "    ('V9â€¢ QueenRaaa.TT', 'sati siapaa anjirrrrğŸ˜­ğŸ˜­', '0'),\n",
        "    ('D3314', 'Keluar ga tuh sardi nya ğŸ˜…ğŸ˜‚', '0'),\n",
        "    ('Raff', 'Itu Surti ğŸ˜­', '0'),\n",
        "    ('wisnusajaa', '@Donal crew @G-NONG audio ğŸ”Š komen e mbah', '1'),\n",
        "    ('littlegirl11', 'sarno ga si', '1'),\n",
        "    ('Cussss', 'sardi yo lanang tohhğŸ˜­', '1'),\n",
        "    ('satriaarmdni', 'ferdiğŸ—¿', '1'),\n",
        "    ('â€” ğ™šá¯“á¡£ğ­©à¹‹à£­ ğ–Ÿğ–†ğ–†\\'ğ–˜ â­‘', 'MAU NYOBA TAPI GAADA DUIT ğŸ˜', '3262'),\n",
        "    ('Gheaqiu', 'samağŸ˜­ğŸ˜­ğŸ˜­', '0'),\n",
        "    ('â€” ğ™šá¯“á¡£ğ­©à¹‹à£­ ğ–Ÿğ–†ğ–†\\'ğ–˜ â­‘', 'iyaa iyaa', '0'),\n",
        "    ('exa\\'sh', 'kepikiran sampe situ ğŸ˜­', '1'),\n",
        "    ('â€” ğ™šá¯“á¡£ğ­©à¹‹à£­ ğ–Ÿğ–†ğ–†\\'ğ–˜ â­‘', 'ğŸ˜­ğŸ˜­', '2'),\n",
        "    ('Varr_ForeverğŸ¦–', 'Jangan ke rumah nya yağŸ—¿', '29'),\n",
        "    ('xyzaa', 'nabung', '7'),\n",
        "    ('rAaRaa-?!! ğŸš—ğŸ¦', 'emg dia minta?', '0'),\n",
        "    ('KampretID98', 'Sarti kliatan kalem bgt manis', '412'),\n",
        "    ('dheanisa', 'ramah bgt tiap diajak ngomong slalu ngerespon dengan senyum', '8'),\n",
        "    ('krisna_aja', 'vilmei memposting ulangğŸ˜­', '3'),\n",
        "    ('@betty âœ¨', 'orang lain syaratnya follow â sarti syaratnya fhoto âœ”ï¸', '265'),\n",
        "    ('ğŸŒ§ï¸', '5 ribu angkutt', '1088'),\n",
        "    ('pacar mu', 'enak ya jadi cantik', '1660'),\n",
        "    ('N?', 'rumsyah bagiku rada mirip arbie gak sih?', '33'),\n",
        "    ('â€¢Icaaww', 'rumsyah siapa? aku kenal sartiğŸ˜', '28'),\n",
        "    ('Daila ğŸŒ¿ğŸƒ', 'aku nggak bisa bedain sarti sama rumsyah', '26'),\n",
        "    ('ğŸ‘', 'kalo syaratnya cuma foto aku jga mauuâ˜ºï¸ğŸ¤', '32'),\n",
        "    ('Miss Apparel', 'Cantik,ramah + murah senyum', '11'),\n",
        "    ('(ã¥ï¿£ Â³ï¿£)ã¥', 'ka ko ka sarti foto nya sendiri kolo yang satunya lagi berdua sama kakağŸ—¿', '2'),\n",
        "    ('maharani s', 'aku pake emang sewangii dan seawett ituu sumpahh ,btw aku pake yang yummy yaaağŸ˜ğŸ˜', '13'),\n",
        "    ('â˜…à¸‹à¸±à¸¥à¸‹à¹ˆà¸²â˜…', 'sarti yang dari pedalaman aja udh pakai vm.co aku yang luar dari pedalaman aj gak pake ğŸ˜­', '0'),\n",
        "    ('mamah afkar19ğŸ’«', 'ko mirip vilmei', '0'),\n",
        "    ('DAVID SAD STORY ğŸ’”', 'sarti punya aku', '0'),\n",
        "    ('LğŸ€', 'WOY BANGUN WOYY CI VILMEI OTW 22MğŸ˜­ğŸ’˜', '0'),\n",
        "    ('Husnahhusen4', 'masya Allah sarti lebih murah senyum', '0'),\n",
        "    ('dracoo\\'s wife', 'keren bgt extrait de parfume', '0'),\n",
        "    ('canah tea', 'cantik bgt sih â¤ï¸', '0'),\n",
        "    ('ğŸ…°ï¸LLà¼¼á•™á•—', 'kak aku mauuuuğŸ—¿ğŸ—¿', '0'),\n",
        "    ('putri darlings', 'sarti harusnya foto full body', '0'),\n",
        "    ('beby', 'sarti beneran minta hp nya?', '0'),\n",
        "    ('ğŸ”‘KEYğŸ”‘', 'wowww banget sarti wkwk', '0'),\n",
        "    ('__aqeela__', 'sarti enteng dibagian leher ğŸ˜‚ğŸ˜‚', '0'),\n",
        "    ('Bobby', 'Kenapa sarti bisa', '0'),\n",
        "    ('JJK_4ever', 'kemarin juga sarti sama rumsyah di undang ci?', '0'),\n",
        "    ('Reyhan', 'kenapa sarti mau bego?', '0'),\n",
        "    ('DesiNovi', 'pasti lebih banyak foto sarti', '0'),\n",
        "    ('riri', 'itupun sarti yg mungkin dipilih ci?', '0'),\n",
        "    ('indah dewi', 'paling suka yang ini wkwk', '0')\n",
        "]\n",
        "\n",
        "# Pisahkan data menjadi komentar dan likes\n",
        "comments, likes = zip(*[(d[1], d[2]) for d in data])\n",
        "\n",
        "# Buat DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Komentar': comments,\n",
        "    'Like': likes\n",
        "})\n",
        "\n",
        "# Tampilkan DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "vs4LQm2OmLT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "yQENBW0_6y7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Content Rumsyah Baduy di vm.co\n",
        "\n",
        "  Like : 329.7K\n",
        "  \n",
        "  Comments : 1517\n",
        "  \n",
        "  Archive : 14.9K"
      ],
      "metadata": {
        "id": "no6GPgEYn-Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl"
      ],
      "metadata": {
        "id": "ihZWnd5s48rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dat123 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fille/content2_rumsyah.csv')\n",
        "dat123\n"
      ],
      "metadata": {
        "id": "cAaqYYs4oqpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Data komentar dan jumlah like\n",
        "data = \"\"\"\n",
        "rumsyah pas sama cewek ğŸ˜ğŸ˜’ğŸ™„ğŸ«¤,\n",
        "rumsyah pas sama cowok ğŸ¥°ğŸ¤ªğŸ˜˜ğŸ˜†,\n",
        "iyaağŸ˜­ğŸ—¿,\n",
        "sapatau lgi mls ngomong ğŸ¤£ğŸ—¿,\n",
        "bner bgtğŸ˜‚,\n",
        "aku kira pandangan aku doang ğŸ¤£,\n",
        "Kirain gw doang yg berasa gitu ğŸ˜©ğŸ˜©ğŸ˜©ğŸ˜©,\n",
        "tp bukanya Krn belum Deket bgt sama vilmei?,\n",
        "kaya ga mood gitu ga sihh kl sama cewe, pas sm cowo mood bgtt anehğŸ˜­,\n",
        "Pikmi bratiğŸ˜Œ,\n",
        "lahhh iya benerrr, kataku juga gitu apa perasaan aku doang tadinyağŸ¤£,\n",
        "di vt lain dia buat vt sama cowo cengar cengir ramah, pas sm cewe merenguttt ae,\n",
        "ihh ky nya emg gt kak soalnya kan kalo sm cowo dia suka di cieâ€ in otomatis suka baper masa iya sm cewe di cieâ€ in juga,\n",
        "komennya di like dong,\n",
        "di vt lain pas ditanya\\ kekgni sma cwo dia cengar cengir ketawa, disini kok gak nyenengin gtğŸ˜‚,\n",
        "mukanya emang gitu yaelah yakali senyum truss,\n",
        "ngapa sih,\n",
        "klo sarti beda,\n",
        "takut kalah saing,\n",
        "type pick me,\n",
        "Pick me g seh,\n",
        "mnding sama sarti lebih ramah.,\n",
        "woe? di like lohğŸ˜­,\n",
        "kurang excited gitu dianya,,\n",
        "ğŸ—¿,\n",
        "pp kita samağŸ—¿,\n",
        "benerrr,\n",
        "rumsah aslinya baik guys, aku kemaren kerumah dia. tapi emang raut mukanya gitu, tapi aslinya baik ramah dan cantik banget ..,\n",
        "mending sarti cantik luar dalem lah ini cantik di luar doang aslinya munafik ğŸ—¿,\n",
        "iyaa ğŸ¤£ğŸ¤£ğŸ¤£,\n",
        "gatau tuh jir kocakkğŸ˜­,\n",
        "ci vilmei aja ngk ngomong mau ngsih iPhone emng kocak itu rumsyahğŸ˜­ğŸ¤£ğŸ¤£,\n",
        "yang ribet cowomya yang d katain cewemya emng kocak lu pada sdm rendah,dia ajah udah punya ip sbluknya pas potoshoot kocak,\n",
        "oo gtu kak okee,\n",
        "maaf ka mau nanya ko kaka tau klo dia munafik emg nya ada apaa akh ketingalan kek nyağŸ˜­,\n",
        "gara gara monti,\n",
        "YANG MINTA COWOK NYA @Monti Sibolang,\n",
        "yg ngomong di monti jir bukan dia nya ğŸ—¿,\n",
        "dia minta hp grgr hpnya rusak tp dikasih hp advan, terus dia bkin video ktny vilmei gk ngasih iphone,\n",
        "ci rumsyah nama pacar nya monti,\n",
        "ouu si monti muka opet itu nya,\n",
        "ikppppjjl look iu it ijcggkkggkkkjpppplpppluloklppophllkjjjjhjjjhk,\n",
        "aku udah lihat akun dia sama pacar nya,\n",
        "rumsyah sama cewe ğŸ™‚ğŸ™„ğŸ˜,\n",
        "rumsyah sama cowo ğŸ¥°ğŸ˜˜ğŸ˜Šâ˜ºğŸ˜„,\n",
        "rumsyah gk mau klh cntikk Ama ci vilmei,\n",
        "Bener kaya takut inscure gtu sma sma cewek soalny,\n",
        "rumsyah ajak kluar dari baduy, pasti outfitnya cantik'ğŸ˜­,\n",
        "anjrrğŸ˜­,\n",
        "jangan ntar makin tinggi dia ğŸ˜‚,\n",
        "jangan ah,\n",
        "benget na aya dua,\n",
        "we kata siapaağŸ˜­,\n",
        "selamanya maksud akğŸ˜­ğŸ˜ƒ,\n",
        "iya kk emng mau di ajak ke Jakarta ğŸ˜­ğŸ™,\n",
        "wkwk keluar ke kota dia bukan apa,\n",
        "Jgn kak tkut daftar LC nnti klo udh dsna ğŸ™ğŸ»ğŸ˜‚,\n",
        "pretğŸ’¨,\n",
        "apasi?,\n",
        "tapi pemain anying,\n",
        "dia aja minta ke Jakarta,\n",
        "rumsyah sm sarti agak mirip kata akuğŸ˜,\n",
        "iya njir ke samağŸ˜­ğŸ™,\n",
        "Rumsah itu ponakannya sarti, sarti tantenya rumsyah,\n",
        "iya mirip,\n",
        "iyaa woyy,\n",
        "cantikan Sarti menurut aku,\n",
        "cantikan rumsyah ğŸ—¿,\n",
        "gw kira kembarğŸ˜­ğŸ˜­,\n",
        "rumsyah knp kek tertekan gtuğŸ˜­,\n",
        "wkwk,\n",
        "tapi sarti beda ko ramah senyum emg sifatnya gtu rumsyah,\n",
        "Tp klo sm cowok kok ramah meskipun cowoknya orng asing,\n",
        "PULANG GK LO RAKA NUNGGUIN NIH ğŸ˜­ğŸ˜­,\n",
        "cu pulang cu ğŸ—¿,\n",
        "mana bnr lgi,\n",
        "mesti pas dikasih apa itu baru seneng,\n",
        "Nga mau kala cantik diağŸ¤­ kyanya,\n",
        "spill bjunya min,\n",
        "cantiknya tersaingi ituğŸ˜‚ğŸ˜‚,\n",
        "itu rumsyah bilang 'makasih' seharusnya dijawab 'sama-sama'.,\n",
        "maunya sma cowo ka,\n",
        "apalagi sama omÂ²,\n",
        "org beda beda, mungkin Sarti gmpng akrab,\n",
        "eh maksudnya ci vilmei,\n",
        "mungkin karena dia grogi ketemu sama cu vilmei,\n",
        "Tapi cowok bisa d fikirğŸ¤£,\n",
        "kalo sama cwe gituh kalo sama laki baru senyum senyum ğŸ˜,\n",
        "Wkwk hooh ğŸ˜‚,\n",
        "klo yg wawancarai cwok kek nya full senyum,\n",
        "Bukan tertekan tapi kayak mikir apa gitu,\n",
        "bukan tertekan kayak gimna gitu kayak ga suka mls gitu,\n",
        "PALING BETUL CUNNAH BADUY GAKK SIHH. DIA BAIK BANGET TAU:)ğŸ˜­,\n",
        "getol ğŸ—¿,\n",
        "kalo di ajak omong sm cewe pasti liat kemana' tp klo cowo di liat mulu mukanyağŸ˜‚,\n",
        "soalnya bru dpt hpnya advan,ekspetasi diaa dpt ip,\n",
        "org bd' mngkin dia MSI beradaptasi sama ci vilmei,\n",
        "v sama monti girang,\n",
        "maksud?,\n",
        "ga emg dia kl sm cewe gitu coba aja sm cowoğŸ˜¹,\n",
        "tapi dia lebih welcome sama cowo beda sama cewek ke ya udah senyum kaya kebutuhan syuting doang,\n",
        "keliatan bgt attitude nya nolğŸ˜”ğŸ™,\n",
        "mungkin ga suka ci vilme. situ suka ga?,\n",
        "kasian tau endors dia ğŸ˜‚ğŸ˜‚,\n",
        "rasa berak,\n",
        "yg blg ngasi ip sapa anjai??? ğŸ˜­,\n",
        "di kasih hp ipone ternayta Advan,\n",
        "mukanya rumsyah kayak gak senang gitu,\n",
        "dia canggung anjirr bukan tertekan nama nya juga masih 16 thn masih lucu lucu nyaâ˜ºï¸ğŸ˜…,\n",
        "iya padahal vilmei udh jauh Â²dari jkt,\n",
        "KITA GA BISA MENILAI ORG DR MIMIK MUKA NYAA. DOSA LOH JATOH NYA\n",
        "LynaawwğŸ¡\n",
        "yaudah sih gw cmn ksh tau knp serius bngt\n",
        "Fahmi MUA\n",
        "Dia ksna juga bukn cmn mau bantu orang!! Tapi sambil nyari duit\n",
        "Fahmi MUA\n",
        "Batter gasiii?? Yg di dpetin vimeii malah lebih gedee pastii!! Sudut pndang nya bnyak yg harus kita pertimbangin untuk mngmbil opini jdi jngn fahamin satu ajaa\n",
        "park.jjayğŸ¦…ğŸ¦…\n",
        "baru tau kalo rumsyah punya tiktokğŸ˜‚\n",
        "Ná´œÉ´ãƒƒï¸\n",
        "whh mksii yaa\n",
        "park.jjayğŸ¦…ğŸ¦…\n",
        "@rumsyahbaduycom\n",
        "Ná´œÉ´ãƒƒï¸\n",
        "ini bknny TT nya parfum nya vilmei yah?? klw mmng rumsyah punya TT cb tag dong\n",
        "Natalia\n",
        "rumsyah bilek : ternyata gue kalah cantikğŸ¤£\n",
        "âœ¨âœ¨fitryğŸ’–\n",
        "ğŸ˜­\n",
        "RIA CPYY\n",
        "sepemikiran njir ğŸ˜‚\n",
        "Nona viaãƒ’ãƒ¥ã‚¬ğŸ§\n",
        "tatapan rumsah kaya tatapan tetangga ku ke akuğŸ˜­\n",
        "Mbaning98\n",
        "Iyah ngliatnya kaya ga mau kalah saing kecantikan nya ni anakğŸ™‚\n",
        "Alessio\n",
        "terlalu sipit. Rumsyah lebih manisğŸ˜šğŸ˜šğŸ¥°ğŸ¥°\n",
        "iyaaa\n",
        "cntik co vilmei la\n",
        "@pinatupangğŸ˜˜\n",
        "rumsyah klo sama ceweğŸ˜’ğŸ˜‘\n",
        "kalo sama cowok ğŸ¥°ğŸ˜…ğŸ˜\n",
        "@pinatupangğŸ˜˜\n",
        "mana iya lagiğŸ˜µğŸ™\n",
        "gyye\n",
        "di like adminya lowwhhğŸ˜­\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "rumsyah=rumah syusahğŸ—¿\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "ya emng\n",
        "Riilâ€¢â„¢Â©\n",
        "emng bener sihğŸ™ƒğŸ™ƒ\n",
        "â€¢Â°AraaVianaÂ°â€¢\n",
        "loh riil\n",
        "Riilâ€¢â„¢Â©\n",
        "apeniğŸ™ƒ\n",
        "â€¢Â°AraaVianaÂ°â€¢\n",
        "ril\n",
        "ğŸ§Â°.â€¢Æ‡Î±Î±~ğŸ’\n",
        "jk ada batasnya\n",
        "Piaa\n",
        "ğŸ˜­ğŸ˜­\n",
        "desiiğŸ€ğŸ‹\n",
        "ğŸ˜­ğŸ˜­ğŸ—¿\n",
        "zifaaa, ğŸ’ƒ\n",
        "mereka tuh banyak duit tapi cuma karna tradisi mereka terlihat susah\n",
        "iyaa bebas kok kan aku cuma bilang bjirlah,dedhi oreng tak eddhep moseng jehğŸ¤£\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "ya seterah gw mau komen ap hidup2 gw ğŸ˜’\n",
        "siapa yg ngatur luğŸ¤£cuman bilang kok fiuhhh\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "...\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "yaudh gk ush ngatur2 seterah gw lh mau komen ap kok situ yang panas\n",
        "trsrh aku dong ğŸ¤£\n",
        "fensgwsmğ–¤ğŸ‘¹\n",
        "yaudh lu kalo gk suka komenan gw ya skip lah su\n",
        "bisanya hina doang lu hadehh gsuka skip lah su\n",
        "ror\n",
        "omongan nya dijaga\n",
        "Fathan Danindra Collection\n",
        "padahal si ci vilmei setulus itu loh ma dia baiknyağŸ˜’\n",
        "Fathan Danindra Collection\n",
        "lah iya kan ka ..telepas dr apapun merk nya. .yg penting kan bersyukur udh di kasih yaa\n",
        "ns.\n",
        "rumsyah:ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’ğŸ˜’\n",
        "Tiara (epep)ğŸ’—\n",
        "baduy agama apa?\n",
        "plis jawa\n",
        "RipZuko\n",
        "Sunda wiwitan\n",
        "wallll28\n",
        "bukan jawa kak\n",
        "ellâ˜†\n",
        "Sunda wiwitan\n",
        "DVL | PINO\n",
        "dh gua tebak luh suka kanğŸ˜\n",
        "pilo.aja sih\n",
        "Sunda wiwitan\n",
        "Michi:(\n",
        "Jawa timur\n",
        "mulfandâ¤â¤\n",
        "Sunda Wiwitan\n",
        "â˜…ASHILAâ˜… ğŸ’OPEN TOP UPğŸŒ·\n",
        "karinakuan\n",
        "sunda wiwitan\n",
        "Salselva mika\n",
        "sunda kak sundah cukupğŸ˜­\n",
        "ğŸ«¨\n",
        "sunda wiwitan, kepercayaan asli Indonesia yg di anut seluruh orang baduy\n",
        "urcutespideyy\n",
        "tuh mata kalo diajak ngomong gapernah liat muka ci vilmei perasaan\n",
        "ğ™ğ™¤ğ™¢ğ™¯âš¡\n",
        "gua juga gitu ga bisa eye contact gimana caranya biar bisağŸ˜­ğŸ˜­ğŸ˜­\n",
        "afifah!?\n",
        "gw kalo ngomong juga gak pernah ngeliat mata gitu kayak gimana gitu\n",
        "iniiceeceeyy\n",
        "canggung gt gasi?\n",
        "?\n",
        "cantik banget kak rumsyahğŸ˜\n",
        "ğ˜¼ğ™£ğ™¨ğ™ ğ™®\n",
        "kalo di manado, muka kek gitu cuma di bawah standarğŸ—¿\n",
        "uda aku spil ya bisa cek vidio\n",
        "ntp roknya dahkuspilinkno 87ğŸ¥°c\n",
        "?\n",
        "likenya bilek: ğŸ—¿ğŸ—¿\n",
        "bii\n",
        "tpi attitude nya jelek.\n",
        "Nikita\n",
        "B aja\n",
        "rizwan401\n",
        "cantikan rumsyah daripada pilmei\n",
        "Kapocino\n",
        "Tapi banyak duit nye pilmei dri rumsyahğŸ¤£\n",
        "NIEAL\n",
        "Jawapan bodoh\n",
        "puput02jhi\n",
        "kak kenapa sama rumsyah mulu nggah sama sartiğŸ—¿\n",
        "Fani? ap kntl!!\n",
        "sudah\n",
        "PuputtiaraNew\n",
        "sama cewek ga gairah klo ngobrol sma cowo smngt bgt\n",
        "BilaağŸ¦‹ğŸ¦„\n",
        "bnr anjid\n",
        "insial D\n",
        "berarti ci vilmei ke baduy luar kah\n",
        "i Miss u\n",
        "iyaa kaa, liat aja di yt civilmei, seruuy bangettttyyy\n",
        "insial D\n",
        "iya kk aku pernah denger itu baduy dalam\n",
        "Mamah Melvin ğŸ£\n",
        "iya Kalo Baduy Dalam mah pakaiannya juga beda Warna bajunya Warna putih sama Rok/Celananya warna hitam\n",
        "insial D\n",
        "iya bener tuhh\n",
        "baduy dalam ga boleh direkam\n",
        "insial D\n",
        "ohh ya\n",
        "niaaâ€½\n",
        "pake nnya\n",
        "shoptiktpkgros\n",
        "di kasih HP advanğŸ˜‚ğŸ˜‚\n",
        "ShofiaOfficial Storeee29.\n",
        "Pada kenapa sih kalo di kasih hp advanğŸ˜ Orang tuh bersyukur apa pun yg dikasih\n",
        "cha\n",
        "coba lu kasi dia ip,bs?\n",
        "Kikuy\n",
        "Bersukur apapun itu pemberian\n",
        "BellağŸ§š\n",
        "ya emng apa salah nya ngasi hp Advan yg penting bisa di pake!!emng Lo bisa kasii ngaca lah\n",
        "Aquarius.CancerğŸ¦‹ğŸŒ¼\n",
        "iya jirrr,, masih untung yaa ada yg mau ngasih secara cumaÂ²\n",
        "ã…¡ ğ€ğŸ• ğ‹ğšğš\n",
        "ya emang knp jirr,lagian g ada persiapan jga+vilmei jga g bilang klo mau ngasih ho advan\n",
        "â€”ğ³ğšğšâ‹†\n",
        "yaudah deh gimana kalo Lo yang ngasih hp iPhone ke rumsyah\n",
        "Naditha QinarağŸ’\n",
        "lah segitu juga di kasih bersyukur\n",
        "nona N\n",
        "emang ada keharusan kl tiktoker banyak follower dilarang ngasih hp Advan?\n",
        "vm.co Â· Kreator\n",
        "ğŸ¥°ğŸ¥°ğŸ¥°\n",
        "Nurhayati\n",
        "syukur ada yg ngasih hp\n",
        "Reztiie Ramadhaniie\n",
        "bersyukur woilah, yg penting masih bisa buat komunikasi..\n",
        "Liaa . mengikuti\n",
        "emang lho mampu beli in?\n",
        "@febri123com\n",
        "kalau aq di kasih hp AQ syukuri knpa dengan hp Advan\n",
        "ğŸ…°ï¸iniii^áª²áª²áª²\n",
        "utamakan bersyukur.. ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
        "Lala\n",
        "dikasih aja mah bersyukur harusnyağŸ¥± ditambah duit lagi\n",
        "FÄ—breeğŸª·\n",
        "Siapa suruh bilang mau minta hp doang gk bilang hp apa sebut aja kalo mau ipğŸ¤£\n",
        "<<pikii kayeye>>\n",
        "lu gk liat disamping vilmei apa\n",
        "(kemungkinan mau dikasih ke rumsyah)\n",
        "chiko0133\n",
        "Bner nmany jg d kasih mau dapet barang yg bnerâ€™ di suka y beli sndiri\n",
        "omanddthegreates\n",
        "lu aja yang ngasih biar iphone\n",
        "19 september me ultahhğŸ‰ğŸ˜»\n",
        "lu aja yg beliin iphoneğŸ˜¹\n",
        "yxnnrahma\n",
        "kenapa ga lu aja yg ngasih hp ipğŸ˜\n",
        "zaa\n",
        "lu aja yang ngasih orang ci vilmei udah bilang kalo nggak ada persiapan ,ğŸ¤—ğŸ”¥\n",
        "lexi\n",
        "dia juga ngasihnya bukan hp advan yang murah kali\n",
        "kioooğŸ™‹\n",
        "emang lo bisa ngasih ip??\n",
        "NEYYà­¨à§\n",
        "ywdah sna kasi iphone sm lu\n",
        "GMMYGBEAR\n",
        "lu udah kasi apa aja buat orang\n",
        "nna~\n",
        "apasih, syukur di kasih. lagian ci vilmei juga bilang di vt ny \"aku ad bawa hp atau ga\" dan mungkin kebetulan ya dia cuma bawa advan\n",
        "tiul\n",
        "masih untung di kasih,kalo mau yg lain kerja dpt dwt beli sendiriii\n",
        "Jayzz | capcut\n",
        "yaudah lu aj beli in ip\n",
        "Riry\n",
        "vilmei bilang dia gak bawa hp IP adanya di mobil cuma itu\n",
        "pangeran oreo\n",
        "kan bisa diblng rumsyah aku ga bawa hp nnti aja pas udh di jakarta aku kirimin ğŸ—¿\n",
        "albi\n",
        "iyaiaya,bersyukur sih emang Cuman skelas artis followery byk ngasihnya advan.\n",
        "Fyy Aja\n",
        "daripada lu gak ngasih ğŸ˜‚\n",
        "Intan febby\n",
        "lu bisa kasih apa\n",
        "Levani Meyra Fadillahâ™¥ï¸\n",
        "lo ksh hp ke dia bisa ga\n",
        "h for bibzxğŸ‘½\n",
        "dari pada lu g ngasihğŸ¤ªğŸ¤ª\n",
        "cicipisces\n",
        "banyak banyak bersyukur ya...\n",
        "Pinter baik cantik\n",
        "emang kenapa kak? kan dikasih\n",
        "uda aku spil ya bisa cek vidio\n",
        "ntp roknya dahkuspilinkno 87ğŸ¥°d\n",
        "pangeran oreo\n",
        "itu tik tokers banyak folowers hp advan itu hp zaman duluğŸ—¿\n",
        "VirgoGirl\n",
        "Coba kasiih ip dong\n",
        "VirgoGirl\n",
        "Masii mending di bagi, bersyukur lah\n",
        "widya olshop\n",
        "emng lu mau ngasih?\n",
        "bby. gy.sa\n",
        "@LutKurangturu:@VILMEIâœ¨:GabawaaağŸ™ğŸ» aku pikir mereka gak terlalu butuh hp , gaada persiapanğŸ‘ğŸ˜­\n",
        "rizz.amsss\n",
        "ya terus? emang lo bisa ngasih juga? ğŸ˜‚\n",
        "nurdonoğŸ‘‘\n",
        "kek nya rumsya jadi iklan parfum bgus dehhhğŸ˜ğŸ˜\n",
        "uda aku spil ya bisa cek vidio\n",
        "ntp roknya dahkuspilinkno 87ğŸ¥°f\n",
        "nurdonoğŸ‘‘\n",
        "yakan klo di jakian iklan skincare atau parfum bgus banget tambah cantik\n",
        "saya\n",
        "duhh kulitnya KK rumsyah sehat bgt woiii\n",
        "BakicotÂ®\n",
        "dalam hati iphone cepat keluarğŸ¤£ğŸ¤£ğŸ¤£\n",
        "~ryllğŸ€\n",
        "ğŸ˜­ğŸ˜­ terlalu ngarep kak ujunya dapet HP advan ğŸ˜­ğŸ˜­\n",
        "Montoon\n",
        "ekspresi rumsyah ğŸ˜³ğŸ˜ğŸ™„ğŸ˜ŒğŸ˜ğŸ¤¨ğŸ˜®â€ğŸ’¨\n",
        "CahyaniğŸ›\n",
        "ngga boleh pake odol,terus kalo sikat gigi gmn ya?\n",
        "KimreetaağŸ°ğŸ¦™\n",
        "Itu sebagian kaya org\" tua yg masih ngikut aturan baduy dalem klo anak\" muda mah udah bebas\"aj mereka aj klo main keluar misal belanja ke alfa pke outfit biasa ga pke kain aku tau krn suka liat\n",
        "uda aku spil ya bisa cek vidio\n",
        "ntp roknya dahkuspilinkno 87ğŸ¥°e\n",
        "ğ™–ğ™¯ğ™ªğ™£ğ™–\n",
        "sabunnya diganti sama daun, sikat gigitnya pke pasir\n",
        "orang gabut\n",
        "lihat vt @VILMEIâœ¨\n",
        "Anisa. L ğŸ‘€\n",
        "pke sabut kelapa\n",
        "Azka & Azwa\n",
        "mungkin sebagian udh ada yg gosok gigi pake sikat dan odol...kn mereka ngewrung yğŸ™\n",
        "ï®©Ù¨Ù€Ù¨Ù€ï®©ï®©Ù¨Ù€â™¡ï®©Ù¨Ù€ï®©ï®©Ù¨Ù€\n",
        "Batu di gerus/pasir\n",
        "Cahya moon\n",
        "klo sikat gigi ya digosok, masa dikerok ğŸ˜„ğŸ˜„ğŸ˜„\n",
        "korban perasaan\n",
        "kalo baduy luar udah bebas loh\n",
        "heeeennyy Â· ğ–¬ğ–¾ğ—‡ğ—€ğ—‚ğ—„ğ—ğ—ğ—‚\n",
        "baduy dalam/luar bikannya tetep gaboleh ya? cmiiw\n",
        "korban perasaan\n",
        "yang gaboleh baduy dalam kak\n",
        "KentangKunnn\n",
        "rumsyah pick me girl\n",
        "ğ”¦ğ”©ğ”ğ”\n",
        "wkwk\n",
        "Vaa\n",
        "rumsyah : rumah syusah\n",
        "Vaa\n",
        "Eh iya maapp ğŸ˜”ğŸ™\n",
        "ror\n",
        "omongan nya dijaga kak\n",
        "JKT48\n",
        "kak kata nya di Dubai gak boleh bawa hp\n",
        "abcdelma\n",
        "ko dubaiğŸ˜­\n",
        "slvers\n",
        "njir ngakakğŸ˜­\n",
        "syifaaw\n",
        "biarin aja biarin ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­\n",
        "ğ’É¦Î±Î± â™¡ï¸\n",
        "Di DUBAI? ğŸ˜­\n",
        "Strawberrycute11\n",
        "jauh banget kak mo ke dubaiğŸ˜­ğŸ˜­\n",
        "JKT48\n",
        "eh maaf sala ketikğŸ˜\n",
        "ğœê«€××…Ü»İŠÊ·áµ‰â‚šáŸ°â³Ù¥Ë¢ ğŸ³\n",
        "badui ka badui bukan dubai dubai mah negara ğŸ˜”ğŸ˜\n",
        "Ã©lOove\n",
        "komen terngakak d vt ini\n",
        "VinğŸ¬\n",
        "salah kk yng bener di daboy\n",
        "JKT48\n",
        "sorry\n",
        "RğŸŒ·ğŸ¼\n",
        "baduy dalem yg gk boleh tapi baduy luar boleh\n",
        "FlashManagement\n",
        "wah Dubai dong ğŸ˜­\n",
        "nÄ“bula, j.b ğŸ‡¸ğŸ‡©\n",
        "BADUY BUKAN DUBAI ANJRTğŸ˜­ğŸ˜­\n",
        "ğ—²ğ˜†ğ˜†ğ—®? ğ—œ'ğ—º ğ—µğ—²ğ—¿ğ—²ğŸ™‹â€â™€ï¸\n",
        "baduy anjir bukn dubaiğŸ˜­ğŸ—¿\n",
        "ğŸ¦–ğŸ‰\n",
        "ada parfum yg utk cowo g?\n",
        "vm.co Â· Kreator\n",
        "adaa loh yang variant warna biru\n",
        "ğŸ‘¾\n",
        "Sarti:Terserah ci vilmei aja\n",
        "rumsyah: request Mulu\n",
        "yeryxnğŸŒ·\n",
        "muka rumsyah pas ketemu vilmei : ğŸ˜’\n",
        "muka sarti pas ketemu vilmei : ğŸ˜\n",
        "sarti orgnya asik soalnya\n",
        "bulaneditzğŸ­\n",
        "rumsyah kayak tertekan ğŸ—¿\n",
        "salll? yes sirğŸ’ğŸ’«\n",
        "iya\n",
        "Bintang Cahaya\n",
        "rumsyah:rumah syusyah\n",
        "YANI HEGI97\n",
        "ekspresinya kek gk senang gtw pdhl vilmei tulus lohğŸ˜Š\n",
        "heiyou07h\n",
        "teman kampung gw bnyk yg kaya rumsyah, ngesok\n",
        "rifaaa(à¹‘â™¡âŒ“â™¡à¹‘)\n",
        "Baduy dlm GIMAN a\n",
        "ANANDITAâ¤\n",
        "rumsyah depan vilmei:ğŸ—¿ğŸ˜ğŸ˜’â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ¤¨ğŸ˜¡\n",
        "sarti depan vilmei:ğŸ¥°â¤ğŸ‘â˜ºğŸ˜ŠğŸ¤£ğŸ˜³ğŸ˜ŠğŸ˜ŠğŸ˜˜ lebih sopan sartiğŸ‘ğŸ‘\n",
        "adinda\n",
        "rumsyah muaknya kaya gak suka tuh ci\n",
        "hayatihayati6961\n",
        "bangun woi ci vilmei udh 51MğŸ˜\n",
        "sallwaa\n",
        "rumsyah sama cewek : ğŸ™„ğŸ˜ğŸ˜’\n",
        "rumsyah sama cowok : ğŸ¥°ğŸ˜ğŸ˜˜\n",
        "SainganmuğŸ¥º\n",
        "Tim sartiğŸ¥°\n",
        "ç»´å¥¥(vio)\n",
        "rumsyah kaya liatin uang ny ngga si?\n",
        "@ayyunyu42\n",
        "mending Sarti lahhh,\n",
        "karna orangnya asik welll\n",
        "KepoğŸ—¿\n",
        "rumsya rumah syusahğŸ˜€ğŸ™ğŸ»\n",
        "Anira\n",
        "dia ramah tpi ke cowo.ğŸ˜©\n",
        "GadisKecilYngMemilikiMataIndah\n",
        "Aku lihat lihat ja Rumsyah mirip ArbieğŸ˜£\n",
        "caramelca3\n",
        "Gw pilih sarti sama rumsyah soalnya agak kasian sama rumsyahğŸ˜­\n",
        "alexandra\n",
        "rumsyah knp si mukanya gtu mulu\n",
        "MIQAILLANY\n",
        "á´€á´˜á´€sÉªÊœ á´‹á´€ÊŸÉªá´€É´ á´›á´œÊœ ÊŸá´ á´‹á´€ÊŸá´ á´€á´…á´€ á´…Éª á´˜á´sÉªsÉª Ê€á´œá´sÊá´€Êœ É¢á´É´?\n",
        "manusiabumiiii\n",
        "apa banget si rumsyah wkkw\n",
        "chila chiechie\n",
        "aq jg pkai varfum vilmei\n",
        "ğŸ¤—\n",
        "aku suka rumsyah\n",
        "Greyy ||\n",
        "rumsyah bujang\n",
        "nik\n",
        "Ngapain sihh si vilmei masih baik sama itu org ğŸ™„\n",
        "zildjianalfaridzy\n",
        "BANGUN WOI CI VILMEI OTW 52 JT\n",
        "rechulll\n",
        "ga usah sama rumsyah ci .. ufah HEPI2 aja sama sarti ... biar aman nyaman dan kita yg nonton juga HEPI\n",
        "â¤ï¸Marsyapixzaâ¤ï¸\n",
        "merusak budaya baduyğŸ˜\n",
        "mayathidup\n",
        "Advan\n",
        "nyyaâ˜†\n",
        "apa kah rumsyah pancak silat?\n",
        "user331120349630\n",
        "salam kenal dari Pontianak Kalimantan Barat\n",
        "âœ¨ğ’ğ’ğ’ğ’‚ ğ’“ğ’†ğ’—ğ’‚âœ¨\n",
        "aku mau parfum nya cuma gk boleh sama orang tuaağŸ˜”\n",
        "Rafa kamil Altamis\n",
        "magrib banget\n",
        "anaksoleh\n",
        "kalo sikat gigi gmna\n",
        "just tin doank\n",
        "bayangin kt ngomong eh dia datar ajğŸ™„\n",
        "titian van jhona\n",
        "ngasihnya seru yg dikasih b aja, kl gw udh heboh jg itu biar yg ngasih sneng\n",
        "Eful\n",
        "hay\n",
        "cacaaca~11\n",
        "klenn lihat muka nya rumasyah ke mana\n",
        "ahmad yani\n",
        "ğŸ˜ğŸ˜p\n",
        "urlove.ntan\n",
        "senyum apa senyum\n",
        "Cannnâ™›\n",
        "\"bolehÂ² aj siehğŸ˜’ğŸ˜ğŸ—¿\"\n",
        "uci\n",
        "@UKSAL. 13 in hee\n",
        "kaiyllaâ­’Öºğ“² ğŸŒ· Ö´Ö¶Ö¸â­’Öº Ö´Ö¶Ö¸\n",
        "@jee @syifa Ade nya rumsyihğŸ˜­\n",
        "suharaafnan\n",
        "ğŸ˜³ğŸ˜³ğŸ˜³\n",
        "â˜†\n",
        "ğŸ˜³ğŸ˜³ğŸ˜³\n",
        "ifahhhhh\n",
        "@rchmdwastti\n",
        "raa\n",
        "â˜ºâ˜ºâ˜º\n",
        "PikacuğŸ¦‹\n",
        "ğŸ‘ğŸ‘ğŸ‘\n",
        "apriliamahardika6\n",
        "ğŸ”¥\n",
        "-\n",
        "1 hari 1 fakta\n",
        "rumsyah pickmeğŸ˜‚.\n",
        "n\n",
        "kliatan bnget anjr dari mukanya, diem\" pemain jirr\n",
        "prenjon\n",
        "cantikk tapi hatinyaaa\n",
        "lanjutkan kawann............\n",
        "AlexağŸ¦–\n",
        "ci VILMEI otw 52M\n",
        "I,m Boyy\n",
        "wdextragame Willie Salim udah tayang cek di yt\n",
        "15j yang lalu\n",
        "tasya26\n",
        "kmrn gua ke snh trs ibuÂ² bilang \"ikut ke Bogor yu\" langsung bilang \"ogah\"anjir\n",
        "ğ™ğ™£ğ™˜ğ™šğ™¨ğ™¨ ğ™€ğ™§ğ™¡ğ™–ğ™©ğ™ğ™ğŸ¥€\n",
        "mukanya aja kek gak peduli civilmey ngomong apa kek bodoamat.\n",
        "alvinghairi\n",
        "WILISALIM KALAHIN MR.BEASTğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n",
        "kaylaa a a\n",
        "mlpo\n",
        "â˜…ğ‘†ğ‘’ğ‘ğ‘Ÿğ‘’ğ‘¡ğ‘ğ‘ğ‘\n",
        "Sarti lebih cntik dari rumsyah\n",
        "\"\"\"\n",
        "\n",
        "# Pisahkan string menjadi list berdasarkan baris\n",
        "comments = data.strip().split('\\n')\n",
        "\n",
        "# Membuat DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Komentar': comments\n",
        "})\n",
        "\n",
        "data\n"
      ],
      "metadata": {
        "id": "SPs3mcfeDk_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtEYCalhSSlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Instagram"
      ],
      "metadata": {
        "id": "ebQKfpKj48us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instagram_er = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Fille/instagram ER.xlsx')\n",
        "instagram_er.head()"
      ],
      "metadata": {
        "id": "d4dVdmw-O8S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})"
      ],
      "metadata": {
        "id": "lFKX6oEJRUmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand the variables\n",
        "pd.options.display.max_colwidth = 100\n",
        "pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Fille/instagram ER.xlsx', index_col=0)"
      ],
      "metadata": {
        "id": "OdVjTKawRelk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(instagram_er.columns)\n"
      ],
      "metadata": {
        "id": "Cz_91wqiSYGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into X and y\n",
        "# You can adapt the input and output columns to fit your own data\n",
        "input_cols = ['Like ', 'Comment', 'rate']\n",
        "output_col = ['Date']\n",
        "X = instagram_er[input_cols]\n",
        "y = instagram_er[output_col]\n",
        "\n",
        "# Split the data into training and test data\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.30, random_state= 44)"
      ],
      "metadata": {
        "id": "tPcD4MJrPN-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make two figures so it is better visualized\n",
        "half = len(input_cols)//2\n",
        "\n",
        "fig1=sns.pairplot(\n",
        "    instagram_er,\n",
        "    x_vars=input_cols[:half],\n",
        "    y_vars=output_col\n",
        ")\n",
        "\n",
        "fig2=sns.pairplot(\n",
        "    instagram_er,\n",
        "    x_vars=input_cols[half:],\n",
        "    y_vars=output_col\n",
        ")"
      ],
      "metadata": {
        "id": "SSqeC8e8Sgq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to flatten 2D lists so it can be used by plotly\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "# Set up and fit the linear regressor\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Flatten the prediction and expected lists\n",
        "predicted = flatten(lin_reg.predict(X_test))\n",
        "expected = flatten(y_test.values)"
      ],
      "metadata": {
        "id": "Tq0254c9T8AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Import plotting package\n",
        "import plotly.express as px\n",
        "\n",
        "# Put data to plot in dataframe\n",
        "df_plot = pd.DataFrame({'expected':expected, 'predicted':predicted})\n",
        "\n",
        "# Make scatter plot from data\n",
        "fig = px.scatter(\n",
        "    df_plot,\n",
        "    x='expected',\n",
        "    y='predicted',\n",
        "    title='Predicted vs. Actual Values')\n",
        "\n",
        "# Add straight line indicating perfect model\n",
        "fig.add_shape(type=\"line\",\n",
        "    x0=0, y0=0, x1=50, y1=50,\n",
        "    line=dict(\n",
        "        color=\"Red\",\n",
        "        width=4,\n",
        "        dash=\"dot\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Ogwhs0ofUWFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(instagram_er.columns)"
      ],
      "metadata": {
        "id": "WMKfXwxrbrkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Combined data from both sets\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Fille/instagram ER.xlsx')\n",
        "\n",
        "# Convert data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['Like '], marker='o', linestyle='-', color='blue')\n",
        "plt.title('Instagram Like')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Like')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the plot\n",
        "save_path = '/mnt/data/time_series_plot.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "save_path"
      ],
      "metadata": {
        "id": "oMFKxvWZbjjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Combined data from both sets\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Fille/instagram ER.xlsx')\n",
        "\n",
        "# Convert data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['Comment'], marker='o', linestyle='-', color='blue')\n",
        "plt.title('Instagram Comments')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Comment')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the plot\n",
        "save_path = '/mnt/data/time_series_plot.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "save_path"
      ],
      "metadata": {
        "id": "obQ-tzhIZ4w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Combined data from both sets\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Fille/instagram ER.xlsx')\n",
        "\n",
        "# Convert data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['rate'], marker='o', linestyle='-', color='blue')\n",
        "plt.title('Instagram rate')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('rate')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the plot\n",
        "save_path = '/mnt/data/time_series_plot.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "save_path"
      ],
      "metadata": {
        "id": "VAMD58xFcfbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Shopee Anlysis"
      ],
      "metadata": {
        "id": "k5oohhCI5Axk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "_eGVdDHD40Og"
      }
    }
  ]
}